{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns; sns.set(color_codes=True)\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "# see sqlalchemy docs for how to write this url for your database type:\n",
    "filepath=\"C:\\\\Users\\\\pkavikon\\\\Desktop\\\\stopwords.txt\"\n",
    "\n",
    "def read_file_stopwords(filepath):\n",
    "    words=[]\n",
    "    with open(filepath) as f:\n",
    "        for line in f:\n",
    "            words.append(line.strip().replace(\"'\",\"\"))\n",
    "    return words\n",
    "\n",
    "\n",
    "engine = create_engine('postgresql+psycopg2://postgres:password@localhost/TweetsDatabase')\n",
    "print(\"Started\")\n",
    "df = pd.read_sql_query(\"select  t.*,f.followers from tweetsTable as t inner join followerstable as f ON t.postdate = f.date order by postdate desc\", engine)\n",
    "df.fillna(value=0, inplace=True)\n",
    "y=df[\"retweets\"]\n",
    "del df['retweets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-12-04 14:28:44,558 : INFO : collecting all words and their counts\n",
      "2017-12-04 14:28:44,559 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-12-04 14:28:44,608 : INFO : PROGRESS: at sentence #10000, processed 167371 words, keeping 19551 word types\n",
      "2017-12-04 14:28:44,627 : INFO : collected 23521 word types from a corpus of 208866 raw words and 12639 sentences\n",
      "2017-12-04 14:28:44,628 : INFO : Loading a fresh vocabulary\n",
      "2017-12-04 14:28:47,095 : INFO : min_count=1 retains 23521 unique words (100% of original 23521, drops 0)\n",
      "2017-12-04 14:28:47,096 : INFO : min_count=1 leaves 208866 word corpus (100% of original 208866, drops 0)\n",
      "2017-12-04 14:28:47,158 : INFO : deleting the raw counts dictionary of 23521 items\n",
      "2017-12-04 14:28:47,161 : INFO : sample=0.001 downsamples 40 most-common words\n",
      "2017-12-04 14:28:47,164 : INFO : downsampling leaves estimated 174459 word corpus (83.5% of prior 208866)\n",
      "2017-12-04 14:28:47,164 : INFO : estimated required memory for 23521 words and 500 dimensions: 105844500 bytes\n",
      "2017-12-04 14:28:47,240 : INFO : resetting layer weights\n",
      "2017-12-04 14:28:47,721 : INFO : training model with 4 workers on 23521 vocabulary and 500 features, using sg=0 hs=0 sample=0.001 negative=5 window=25\n",
      "2017-12-04 14:28:48,750 : INFO : PROGRESS: at 75.38% examples, 646798 words/s, in_qsize 8, out_qsize 0\n",
      "2017-12-04 14:28:49,035 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-12-04 14:28:49,059 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-12-04 14:28:49,061 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-12-04 14:28:49,065 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-12-04 14:28:49,068 : INFO : training on 1044330 raw words (872359 effective words) took 1.3s, 650834 effective words/s\n",
      "2017-12-04 14:28:49,085 : INFO : training model with 4 workers on 23521 vocabulary and 500 features, using sg=0 hs=0 sample=0.001 negative=5 window=25\n",
      "2017-12-04 14:28:50,107 : INFO : PROGRESS: at 74.28% examples, 644385 words/s, in_qsize 8, out_qsize 0\n",
      "2017-12-04 14:28:50,391 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-12-04 14:28:50,411 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-12-04 14:28:50,415 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-12-04 14:28:50,438 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-12-04 14:28:50,440 : INFO : training on 1044330 raw words (872399 effective words) took 1.4s, 646165 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "872399"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "import gensim, logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "sentences = []\n",
    "for index, row in df.iterrows():\n",
    "    sentences.append(row[\"textfiltered\"].split())\n",
    "# train word2vec on the two sentences\n",
    "model = gensim.models.Word2Vec(sentences, min_count=1, window=25 ,size=500,workers=4)\n",
    "\n",
    "model.train(sentences, total_examples=model.corpus_count,epochs=model.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'obama', 0.9980841875076294), (u'VERY', 0.997459888458252), (u'clear', 0.997322678565979), (u'bill', 0.9972741603851318), (u'shell', 0.9967942237854004), (u'market', 0.9963564276695251), (u'FORGOT', 0.9960209131240845), (u'Ask', 0.9955004453659058), (u'Parenthood', 0.9954447746276855), (u'infrastructure', 0.9951733946800232)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(positive=['Obamacare']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-12-04 14:20:22,861 : INFO : loading projection weights from C:\\Users\\pkavikon\\Desktop\\GoogleNews-vectors-negative300.bin\n",
      "2017-12-04 14:21:19,477 : INFO : loaded (3000000L, 300L) matrix from C:\\Users\\pkavikon\\Desktop\\GoogleNews-vectors-negative300.bin\n"
     ]
    }
   ],
   "source": [
    "model2 = gensim.models.KeyedVectors.load_word2vec_format('C:\\\\Users\\\\pkavikon\\\\Desktop\\\\GoogleNews-vectors-negative300.bin', binary=True)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word 'CrookedHillary' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-e3c05ffe5081>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CrookedHillary'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\gensim\\models\\keyedvectors.pyc\u001b[0m in \u001b[0;36mmost_similar\u001b[1;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[0;32m    338\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m                 \u001b[0mmean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m                     \u001b[0mall_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\gensim\\models\\keyedvectors.pyc\u001b[0m in \u001b[0;36mword_vec\u001b[1;34m(self, word, use_norm)\u001b[0m\n\u001b[0;32m    286\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmost_similar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpositive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrestrict_vocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"word 'CrookedHillary' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "print(model2.wv.most_similar(positive=['CrookedHillary']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
